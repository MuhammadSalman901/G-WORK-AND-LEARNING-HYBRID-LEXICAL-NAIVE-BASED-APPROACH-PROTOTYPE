{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnL1Jnxf0WPt"
      },
      "source": [
        "# **LOADING DATASET**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_WCtqe8pMOb",
        "outputId": "381a62df-cb3b-4c93-a344-95e3d4ec12e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      label                                               text  processed_text\n",
            "0  Positive  ممتاز نوعا ما . النظافة والموقع والتجهيز والشا...             NaN\n",
            "1  Positive  أحد أسباب نجاح الإمارات أن كل شخص في هذه الدول...             NaN\n",
            "2  Positive  هادفة .. وقوية. تنقلك من صخب شوارع القاهرة الى...             NaN\n",
            "3  Positive  خلصنا .. مبدئيا اللي مستني ابهار زي الفيل الاز...             NaN\n",
            "4  Positive  ياسات جلوريا جزء لا يتجزأ من دبي . فندق متكامل...             NaN\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 519 entries, 0 to 518\n",
            "Data columns (total 3 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   label           519 non-null    object \n",
            " 1   text            519 non-null    object \n",
            " 2   processed_text  0 non-null      float64\n",
            "dtypes: float64(1), object(2)\n",
            "memory usage: 12.3+ KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "file_path = 'Arabic_Reviews.tsv'\n",
        "df = pd.read_csv(file_path, sep='\\t')\n",
        "\n",
        "# Display the first few rows of the dataset and summary information\n",
        "print(df.head())\n",
        "print(df.info())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHijdGjK9Ws8"
      },
      "source": [
        "# **PREPROCESSING PHASE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9vjg3RapWaO",
        "outputId": "b424d76a-9973-4716-8dbc-75dedeca5bfa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                text  \\\n",
            "0  ممتاز نوعا ما . النظافة والموقع والتجهيز والشا...   \n",
            "1  أحد أسباب نجاح الإمارات أن كل شخص في هذه الدول...   \n",
            "2  هادفة .. وقوية. تنقلك من صخب شوارع القاهرة الى...   \n",
            "3  خلصنا .. مبدئيا اللي مستني ابهار زي الفيل الاز...   \n",
            "4  ياسات جلوريا جزء لا يتجزأ من دبي . فندق متكامل...   \n",
            "\n",
            "                                      processed_text  \n",
            "0  ممتاز نوعا النظافه والموقع والتجهيز والشاطيء ا...  \n",
            "1  احد اسباب نجاح الامارات ان شخص الدوله يعشق ترا...  \n",
            "2  هادفه وقويه تنقلك صخب شوارع القاهره الي هدوء ج...  \n",
            "3  خلصنا مبدءيا اللي مستني ابهار زي الفيل الازرق ...  \n",
            "4  ياسات جلوريا جزء يتجزا دبي فندق متكامل الخدمات...  \n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "# Define a basic list of Arabic stopwords manually\n",
        "basic_arabic_stopwords = {\n",
        "    'و', 'في', 'من', 'إلى', 'على', 'مع', 'عن', 'هذا', 'هذه', 'هو', 'هي',\n",
        "    'ذلك', 'لكن', 'أن', 'إن', 'ما', 'كان', 'كنت', 'كل', 'لم', 'لن', 'لا',\n",
        "    'إذ', 'إذا', 'أيضا', 'فقط', 'بعض', 'أي', 'أو', 'ولا', 'نحن', 'أنا',\n",
        "    'كما', 'حين', 'حيث', 'هنا', 'هناك', 'لذلك', 'لأن', 'بعد', 'قبل', 'عند'\n",
        "}\n",
        "\n",
        "# Function to preprocess the text\n",
        "def preprocess_text(text):\n",
        "    # Remove punctuations, digits, and special characters\n",
        "    text = re.sub(r'[\\d\\W]+', ' ', text)\n",
        "\n",
        "    # Tokenize the text (split by whitespace)\n",
        "    tokens = text.split()\n",
        "\n",
        "    # Normalize text (Arabic specific)\n",
        "    tokens = [re.sub(r'[إأآا]', 'ا', token) for token in tokens]\n",
        "    tokens = [re.sub(r'ى', 'ي', token) for token in tokens]\n",
        "    tokens = [re.sub(r'ؤ', 'ء', token) for token in tokens]\n",
        "    tokens = [re.sub(r'ئ', 'ء', token) for token in tokens]\n",
        "    tokens = [re.sub(r'ة', 'ه', token) for token in tokens]\n",
        "\n",
        "    # Remove stop words\n",
        "    tokens = [token for token in tokens if token not in basic_arabic_stopwords]\n",
        "\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Apply preprocessing to the text column\n",
        "df['processed_text'] = df['text'].apply(preprocess_text)\n",
        "\n",
        "# Display the original and processed text for comparison\n",
        "print(df[['text', 'processed_text']].head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7m2Cinn_Qul"
      },
      "source": [
        "# **APPLYING THE LEXICAL BASED APPROACH**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LIPxGIOpaUB",
        "outputId": "e325376f-7c66-4b04-9f84-8fe6cfedb246"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                text  \\\n",
            "0  ممتاز نوعا ما . النظافة والموقع والتجهيز والشا...   \n",
            "1  أحد أسباب نجاح الإمارات أن كل شخص في هذه الدول...   \n",
            "2  هادفة .. وقوية. تنقلك من صخب شوارع القاهرة الى...   \n",
            "3  خلصنا .. مبدئيا اللي مستني ابهار زي الفيل الاز...   \n",
            "4  ياسات جلوريا جزء لا يتجزأ من دبي . فندق متكامل...   \n",
            "\n",
            "                                      processed_text lexical_sentiment  \n",
            "0  ممتاز نوعا النظافه والموقع والتجهيز والشاطيء ا...          Positive  \n",
            "1  احد اسباب نجاح الامارات ان شخص الدوله يعشق ترا...           Neutral  \n",
            "2  هادفه وقويه تنقلك صخب شوارع القاهره الي هدوء ج...           Neutral  \n",
            "3  خلصنا مبدءيا اللي مستني ابهار زي الفيل الازرق ...           Neutral  \n",
            "4  ياسات جلوريا جزء يتجزا دبي فندق متكامل الخدمات...           Neutral  \n"
          ]
        }
      ],
      "source": [
        "# Define a simple Arabic sentiment lexicon\n",
        "positive_words = {'جيد', 'رائع', 'ممتاز', 'مدهش', 'جميل'}\n",
        "negative_words = {'سيء', 'فظيع', 'ممل', 'سيئة', 'مزعج'}\n",
        "\n",
        "# Function to calculate sentiment score based on the lexicon\n",
        "def calculate_lexical_sentiment(text):\n",
        "    # Tokenize the text\n",
        "    tokens = text.split()\n",
        "\n",
        "    # Calculate positive and negative scores\n",
        "    positive_score = sum(1 for token in tokens if token in positive_words)\n",
        "    negative_score = sum(1 for token in tokens if token in negative_words)\n",
        "\n",
        "    # Determine sentiment\n",
        "    if positive_score > negative_score:\n",
        "        return 'Positive'\n",
        "    elif negative_score > positive_score:\n",
        "        return 'Negative'\n",
        "    else:\n",
        "        return 'Neutral'\n",
        "\n",
        "# Apply the lexical sentiment calculation to the processed text\n",
        "df['lexical_sentiment'] = df['processed_text'].apply(calculate_lexical_sentiment)\n",
        "\n",
        "# Display the original, processed text and the lexical sentiment for comparison\n",
        "print(df[['text', 'processed_text', 'lexical_sentiment']].head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z800C9BdBM7F"
      },
      "source": [
        "# **LABEL CONVERSION FROM STRING TO NUMERIC**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DTrkWa6BTqO",
        "outputId": "2052a9b1-1f23-4953-b179-2097c793ebb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      label  numeric_label\n",
            "0  Positive            1.0\n",
            "1  Positive            1.0\n",
            "2  Positive            1.0\n",
            "3  Positive            1.0\n",
            "4  Positive            1.0\n"
          ]
        }
      ],
      "source": [
        "# Mapping from string labels to numeric labels\n",
        "label_mapping = {'Positive': 1, 'Negative': 0}\n",
        "df['numeric_label'] = df['label'].map(label_mapping)\n",
        "\n",
        "# Display the first few rows with numeric labels\n",
        "print(df[['label', 'numeric_label']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVxf6CDB_dW5"
      },
      "source": [
        "# **APPLYING THE NAIVE BASED MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ng94WnwwpePq",
        "outputId": "741e0930-4125-4901-c27d-c09f0cd8dc7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.625\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      1.00      0.76        63\n",
            "           1       1.00      0.05      0.09        41\n",
            "\n",
            "    accuracy                           0.62       104\n",
            "   macro avg       0.81      0.52      0.43       104\n",
            "weighted avg       0.77      0.62      0.50       104\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Initialize TF-IDF Vectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Fit and transform the processed text\n",
        "X_tfidf = vectorizer.fit_transform(df['processed_text'])\n",
        "\n",
        "# Convert labels to binary (e.g., Positive: 1, Negative: 0)\n",
        "df['label_binary'] = df['label'].apply(lambda x: 1 if x == 'Positive' else 0)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, df['label_binary'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the Naive Bayes classifier\n",
        "nb_classifier = MultinomialNB()\n",
        "nb_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = nb_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyQEV8m8_pJG"
      },
      "source": [
        "# **APPLYING THE HYBRID LEXICAL-NAIVE BASED APPROACH**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFbZJFiAphbA",
        "outputId": "c85af453-7642-4691-b083-4a5546045d98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                text  \\\n",
            "0  ممتاز نوعا ما . النظافة والموقع والتجهيز والشا...   \n",
            "1  أحد أسباب نجاح الإمارات أن كل شخص في هذه الدول...   \n",
            "2  هادفة .. وقوية. تنقلك من صخب شوارع القاهرة الى...   \n",
            "3  خلصنا .. مبدئيا اللي مستني ابهار زي الفيل الاز...   \n",
            "4  ياسات جلوريا جزء لا يتجزأ من دبي . فندق متكامل...   \n",
            "\n",
            "                                      processed_text lexical_sentiment  \\\n",
            "0  ممتاز نوعا النظافه والموقع والتجهيز والشاطيء ا...          Positive   \n",
            "1  احد اسباب نجاح الامارات ان شخص الدوله يعشق ترا...           Neutral   \n",
            "2  هادفه وقويه تنقلك صخب شوارع القاهره الي هدوء ج...           Neutral   \n",
            "3  خلصنا مبدءيا اللي مستني ابهار زي الفيل الازرق ...           Neutral   \n",
            "4  ياسات جلوريا جزء يتجزا دبي فندق متكامل الخدمات...           Neutral   \n",
            "\n",
            "  combined_sentiment  \n",
            "0            Neutral  \n",
            "1           Negative  \n",
            "2           Negative  \n",
            "3           Negative  \n",
            "4           Negative  \n"
          ]
        }
      ],
      "source": [
        "# Function to combine lexical and Naive Bayes predictions\n",
        "def combined_sentiment(lexical, nb_prediction):\n",
        "    # Lexical sentiment (Positive, Negative, Neutral)\n",
        "    if lexical == 'Positive':\n",
        "        lexical_score = 1\n",
        "    elif lexical == 'Negative':\n",
        "        lexical_score = -1\n",
        "    else:\n",
        "        lexical_score = 0\n",
        "\n",
        "    # Naive Bayes sentiment (predicted as 1 or 0)\n",
        "    nb_score = nb_prediction * 2 - 1  # Convert 0 to -1 and 1 to 1\n",
        "\n",
        "    # Combine scores (you can choose a different combination method)\n",
        "    combined_score = (lexical_score + nb_score) / 2\n",
        "\n",
        "    # Determine combined sentiment\n",
        "    if combined_score > 0:\n",
        "        return 'Positive'\n",
        "    elif combined_score < 0:\n",
        "        return 'Negative'\n",
        "    else:\n",
        "        return 'Neutral'\n",
        "\n",
        "# Apply the combined sentiment function\n",
        "df['combined_sentiment'] = df.apply(lambda row: combined_sentiment(row['lexical_sentiment'], nb_classifier.predict(vectorizer.transform([row['processed_text']]))[0]), axis=1)\n",
        "\n",
        "# Display the combined sentiment results\n",
        "print(df[['text', 'processed_text', 'lexical_sentiment', 'combined_sentiment']].head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-NstJwDIwl-"
      },
      "source": [
        "# **CALCULATING ACCURACIES AND COMPARISON**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poomJftSIDnK",
        "outputId": "c49c891e-c4fa-49d8-aa1d-b6c0047475c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Lexical Approach Accuracy: 0.62\n",
            "Naive Bayes Classifier Accuracy: 0.62\n",
            "Combined Approach Accuracy: 0.80\n",
            "\n",
            "Accuracy Comparison:\n",
            "Lexical Approach Accuracy: 0.62\n",
            "Naive Bayes Classifier Accuracy: 0.62\n",
            "Combined Approach Accuracy: 0.80\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Convert the 'label' column to binary for comparison\n",
        "df['label_binary'] = df['label'].apply(lambda x: 1 if x == 'Positive' else 0)\n",
        "\n",
        "# Map lexical sentiment to binary for accuracy comparison\n",
        "def lexical_to_binary(sentiment):\n",
        "    if sentiment == 'Positive':\n",
        "        return 1\n",
        "    elif sentiment == 'Negative':\n",
        "        return 0\n",
        "    else:\n",
        "        return None  # Neutral or undefined sentiments are not considered here\n",
        "\n",
        "df['lexical_binary'] = df['lexical_sentiment'].apply(lexical_to_binary)\n",
        "\n",
        "# Filter out rows where lexical sentiment is Neutral (None)\n",
        "lexical_comparison_df = df.dropna(subset=['lexical_binary'])\n",
        "\n",
        "# Calculate accuracy for the lexical approach\n",
        "lexical_accuracy = accuracy_score(lexical_comparison_df['label_binary'], lexical_comparison_df['lexical_binary'])\n",
        "print(f\"Lexical Approach Accuracy: {lexical_accuracy:.2f}\")\n",
        "\n",
        "# Naive Bayes Classifier accuracy is already computed during model evaluation\n",
        "nb_accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Naive Bayes Classifier Accuracy: {nb_accuracy:.2f}\")\n",
        "\n",
        "# Map combined sentiment to binary for accuracy comparison\n",
        "def combined_to_binary(sentiment):\n",
        "    if sentiment == 'Positive':\n",
        "        return 1\n",
        "    elif sentiment == 'Negative':\n",
        "        return 0\n",
        "    else:\n",
        "        return None  # Neutral or undefined sentiments are not considered here\n",
        "\n",
        "df['combined_binary'] = df['combined_sentiment'].apply(combined_to_binary)\n",
        "\n",
        "# Filter out rows where combined sentiment is Neutral (None)\n",
        "combined_comparison_df = df.dropna(subset=['combined_binary'])\n",
        "\n",
        "# Calculate accuracy for the combined approach\n",
        "combined_accuracy = accuracy_score(combined_comparison_df['label_binary'], combined_comparison_df['combined_binary'])\n",
        "print(f\"Combined Approach Accuracy: {combined_accuracy:.2f}\")\n",
        "\n",
        "# Display all accuracies together for comparison\n",
        "print(\"\\nAccuracy Comparison:\")\n",
        "print(f\"Lexical Approach Accuracy: {lexical_accuracy:.2f}\")\n",
        "print(f\"Naive Bayes Classifier Accuracy: {nb_accuracy:.2f}\")\n",
        "print(f\"Combined Approach Accuracy: {combined_accuracy:.2f}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "environment",
      "language": "python",
      "name": "environment"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
